\chapter{Conclusion and Future Work}
\label{chap:conclusion}

\section{Conclusion}
This dissertation presents our research work on shape modeling and
analysis based on spectral representations and sparsity-driven algorithms.
Our proposed methods provide solutions to a wide range of shape modeling
problems with competitive performance, demonstrating the great potential
of spectral methods and sparse representations in the mesh domain.

We present an innovative approach to 3D mesh compression
by incorporating redundant spectral graph wavelets in dictionary design and using
greedy pursuits to find compressed coefficient approximation.

By formulating surface inpainting as a sparse signal recovery problem,
we propose a novel variational approach for surface inpainting, integrating data fidelity
constraints on the shape domain with coefficient sparsity constraints on the
transformed domain.

We propose a novel informative shape descriptor that combines SGW coefficients and
contour-based statistics for better characterization of feature shape regions. Based on
this descriptor, we develop a generalized feature detection framework, which can integrate different
types of regional descriptors to facilitate widespread applications including partial matching and
model recognition.

We develop an effective feature-driven shape correspondence and retrieval
algorithms. For coarse correspondence, we adopt
tensor-based high-order graph matching to maximizes the
geometric compatibility between features tuples; and for dense matching,
we present a hierarchical shape registration algorithm, generating
correspondence in multiples levels in a coarse-to-fine manner. 
We also propose the Bag-of-Feature-Graph (BoFG) descriptor for shape retrieval, 
which significantly reduce the number of points required for computing 
distributions, comparing with traditional Bag-of-Features descriptors.

\section{Future Work}

There are many possible extensions and improvements related to our current research
work in spectral representations and sparse modeling. Here we introduce some
potential topics.

\subsection*{Shape Editing}

Classical Laplacian mesh editing~\cite{Botsch2008} can be written as a regularized least square
problem. Taking the $x$-coordinate for example, soft constraint Laplacian mesh editing
constructs the new coordinate function by solving the following optimization problem
\begin{equation}
\min_\mathbf{x'} \sum_{j\in C} (x'_j - c_j)^2 + \gamma\|L\mathbf{x'}-L\mathbf{x}\|_2^2,
\end{equation}
where $L$ denotes Laplacian operator, $C$ represents the set of handle vertices, $c_j$ denotes the
coordinate of the handle vertex indexed at $j$, and $\mathbf{x'}$ and $\mathbf{x}$ represent the
original and deformed coordinates, respectively. This formulation ensures that the deformed shape
will preserve the second-order differential geometric information of the original shape while
conforming to the constraints of new handle positions.

Let function $\mathbf{f}=\mathbf{x'}-\mathbf{x}$ and denote the values of $\mathbf{f}$ at
handle vertices as $d_j = c_j - x_j, j\in C$. The optimization problem can be rewritten as

\begin{equation}
\label{eq:laplace-editing}
\min_\mathbf{f} \sum_{j\in C} (f_j - d_j)^2 + \gamma \mathbf{f}^T L^2 \mathbf{f}.
\end{equation}

Expanding $\mathbf{f}$ w.r.t. the Laplacian eigenbasis $\mathbf{\Phi}=\{\mathbf{\phi_k}\}$
as $\mathbf{f}=\sum_k a_k \mathbf{\phi_k}$, Eq.~\ref{eq:laplace-editing} becomes

\begin{equation}
\label{eq:Laplace-editing2}
\min_\mathbf{f} \sum_{j\in C} (f_j - d_j)^2 + \gamma \sum_k \lambda_k^2 a_k^2,
\end{equation}
where $\{\lambda_k\}$ denote the Laplacian eigenvalues.

Analyzing Eq.~\ref{eq:Laplace-editing2}, we can see that the formulation of Laplace
editing penalizing high frequency components (corresponding to larger
$\lambda_k$)~\cite{Rustamov:2009:ICMS}.

Replacing the bi-Laplacian in Eq.~\ref{eq:laplace-editing} with a spectral graph wavelet kernel
$W$ affords flexible design choices regarding the dominating frequencies. Suppose
$W=\mathbf{\Phi}g(t\Lambda)\mathbf{\Phi^T}$, where $g(\cdot)$ is the spectral domain generator
function. Instead of preserving the differential or Laplacian coordinates, we may choose
to preserve wavelet coefficients of different scales after deformation. The spectral expansion
of the optimization problem then becomes

\begin{equation}
\label{eq:sgw-editing}
\min_\mathbf{f} \sum_{j\in C} (f_j - d_j)^2 + \gamma \sum_k g(t\lambda_k) a_k^2.
\end{equation}

Clearly, changing the generator function $g(\cdot)$ or the scale parameter $t$ will
influence the contribution of components of different frequencies in the final reconstruction.

\subsection*{Sparse Representation Learning}
Our current research focuses on \emph{reconstructive} sparse models with predefined dictionaries
composed of analytical functions such as wavelets. Nevertheless, sparse representations also have
great potential as \emph{discriminative} models for pattern recognition, as most meaningful 
high-dimensional signals probably reside in some low-dimensional subspace which can more better revealed
by proper sparse models.

To construct a highly discriminative sparse models, predefined dictionaries are usually not
sufficiently expressive. To improve the sparsity and discriminative power, a dictionary learned from
the data set is much preferred. Given training signals $\{y_i\}_{i=1}^N$, a dictionary that
minimize the overall coefficient sparsity of the training signals can be formulated as follows:
\begin{equation}
\label{eq:dictionary-learning}
\hat{D}=\arg\min_D\sum_{i=1}^N \min_{x_i}\{\|Dx_i - y_i\|_2^2 + \lambda\|x_i\|_1\}.
\end{equation}
The dictionary learning can be handled by algorithms such as K-SVD~\cite{Aharon2006}.

After the dictionary $D$ is learned, for an input signal $y$, a sparse coefficient
representation $\hat{x}$ can be easily computed with respect $D$ using
common $l_1$ formulation:

\begin{equation}
\hat{x} = \arg\min_{x} \{\|Dx - y\|_2^2 + \lambda\|x\|_1\}.
\end{equation}

For shape signals, we cannot directly apply the dictionary learning formulation in
Eq.~\ref{eq:dictionary-learning}, since different models generally have vastly different
graph structures and cannot be easily mapped. Nevertheless, we can adopt or devise appropriate
feature descriptors as a proxy instead of encoding shape signals directly. A highly discriminative
sparse model in the descriptor space should have great potential for tasks such as classification 
and retrieval.

\subsection*{General Graph Signal Analysis}
In this dissertation, our research work concentrates on graph spectral analysis in the context 
of shape modeling. Nonetheless, discrete mesh is only a special type of graph structure. For modeling 
various types of tangible or intangible networks, such as transportation networks and social networks,
graph representation is the natural choice. It is also a common practice to infer graph structures
from data sets without pre-defined networks to help organize the data in a specific way. 
Even for data with existing graph structure, such as 2D images, it is sometimes helpful to cluster 
the original data points into some super nodes and create an alternative graph topology.  
Graph is therefore a very generic data structure as it allows flexible representations of 
relations among data points. 

In recent years, with the explosive increase of data sets generated from Internet and devices 
with sensors, there bas been a growing interest towards adapting and applying signal processing 
techniques for analyzing and modeling graph signals~\cite{ShumanNarangFrossardEtAl2013, SandryhailaMoura2014}.
Currently, there is very few existing works in literature employing sparse and redundant modeling 
methods for graph signal, and it is a promising direction to extend our research in spectral 
representations and sparsity-driven algorithms for the analysis of general graph signals.
